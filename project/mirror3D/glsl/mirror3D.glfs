#version 400

#define OUT_OF_BOUNDS 1
#define DIVISION_BY_ZERO 2
#define DIVERGENCE 3
#define MAX_ITERATIONS_REACHED 4
#define PI 3.14159265359
#define NO_SURFACE 5
#define SURFACE 6
#define BEHIND 7
#define IN_FRONT 8

uniform bool render_quads;
uniform int coloring;
uniform sampler2D depth_image;
uniform sampler2D distortion_map;
uniform sampler2D color_image;
uniform mat4 P_kinect;
uniform vec2 viewport_dims;
uniform bool interpolate_view_matrix;
uniform bool undistort_first;
uniform bool do_lookup_depth;
uniform float depth_in_which_to_lookup;
uniform float depth_scale = 0.001;
uniform int raymarch_limit;
uniform float ray_length;


// this is adapted point.glfs

// vertex_position[4] contains position of passed triangle strip: t1: 0,1,2 - t2: 1,2,3 
in POINT_FS {
	vec4 color;
	float depth_offset;
	vec3 normal;
} fi;

// ***** begin interface of camera.glsl *******************************
#define CONVERGENCE 0
#define SUCCESS 0
uniform float inversion_epsilon;
struct calibration
{
	int w;
	int h;
	float max_radius_for_projection;
	vec2 dc;
	float k[6];
	float p[2];
	float skew;
	vec2 c, s;
};
vec2 image_to_pixel_coordinates(in vec2 x, in calibration calib);
vec2 pixel_to_image_coordinates(in vec2 p, in calibration calib);
vec2 texture_to_pixel_coordinates(in vec2 t, in calibration calib);
vec2 pixel_to_texture_coordinates(in vec2 p, in calibration calib);
int apply_distortion_model(in vec2 xd, out vec2 xu, out mat2 J, in calibration calib);
int apply_distortion_model(in vec2 xd, out vec2 xu, out mat2 J, float epsilon, in calibration calib);
int invert_distortion_model(in vec2 xu, inout vec2 xd, bool use_xd_as_initial_guess, in calibration calib);
// ***** end interface of camera.glsl *********************************

// ***** begin interface of fragment.glfs *****************************
uniform float gamma = 2.2;
void finish_fragment(vec4 color);
void finish_fragment(vec4 color, float depth);
// ***** end interface of fragment.glfs *******************************

// ***** begin interface of holo_disp.glfs ****************************
void compute_sub_pixel_rays(out vec3 ro[3], out vec3 rd[3]);
bool finalize_sub_pixel_fragment(in vec3 rgb, in vec3 depth);
void stereo_translate_modelview_matrix(in float eye, in out mat4 M);
float view_from_fragment_component (const vec2 frag, const int component);
// ***** end interface of holo_disp.glfs ******************************

// ***** begin interface of view.glsl *********************************
mat4 get_modelview_matrix();
mat4 get_projection_matrix();
mat4 get_inverse_projection_matrix();
mat4 get_modelview_projection_matrix();
mat4 get_inverse_modelview_matrix();
mat4 get_inverse_modelview_projection_matrix();
mat3 get_normal_matrix();
mat3 get_inverse_normal_matrix();
// ***** end interface of view.glsl ***********************************

// ***** begin interface of rgbd.glsl *********************************
uint get_depth_width();
uint get_depth_height();
uint lookup_depth(ivec2 xp);
bool construct_point(in vec2 xp, in float depth, out vec3 p);
bool lookup_color(vec3 p, out vec4 c);
bool lookup_color(vec3 p, float eps, out vec4 c);
// ***** end interface of rgbd.glsl ***********************************

// ***** begin interface of mirror3D.glsl *****************************
vec3 ray_trace_pixel(vec3 ro, vec3 rd, out float depth);
mat4 kinect_projection_matrix(float fx, float fy, float cx, float cy, int image_height, float near_clip, float far_clip);
mat4 get_model_view_matrix_translation(vec3 ro);
void march_along(vec3 ro, vec3 rd, int color_channel, out vec4 color, out float depth);
void part_of_march_along(vec3 ro, vec3 rd, int color_channel, out vec4 color, out float depth);
vec4 kinect_to_world_space(vec2 uv);
vec2 world_to_kinect_space(vec3 world_pos);
bool map_sample_to_uv(in vec3 ro, out vec2 xd);
mat4 get_modelview_matrix_view(int color_channel);
vec4 intersect_depth_image_bf();
float get_depth(ivec2 xp);
struct Ray{
	vec3 origin;
	vec3 direction;
};
vec3 vec3_ray(Ray ray);
void set_raylength(Ray inray, out Ray outray, int s, float step_width);
vec4 pixel_coordinates_to_color(vec2 xp);
mat2 rotate_2d(float rotation);
// ***** end interface of mirror3D.glsl *****************************

uniform calibration color_calib;
uniform calibration depth_calib;

void main()
{
	// pure coloring
	if (coloring == 0){
		finish_fragment(fi.color, gl_FragCoord.z + fi.depth_offset);
	
	// calculating normals
	} else if (coloring == 1) {

		finish_fragment(vec4(fi.normal.xyz * 10000, 1.0), gl_FragCoord.z + fi.depth_offset);
	
	// bullying the GPU
	} else if (coloring == 2) {
		finish_fragment(intersect_depth_image_bf(), gl_FragCoord.z + fi.depth_offset);
	
	// working mirror with wrong coordinates
	} else if (coloring == 3) {
		vec3 ro[3], rd[3];
		vec4 hit_color, final_color;
		compute_sub_pixel_rays(ro, rd);
		for (int i=0; i < 3; i++){
			lookup_color(ro[i] + rd[i], hit_color);
			final_color[i] = hit_color[i];
		}
		// remember different modelview matricies for each view inbetween the eyes
		finish_fragment(hit_color, gl_FragCoord.z + fi.depth_offset);
	
	// experimenting
	} else if (coloring == 4) {
		vec3 ro[3], rd[3], eye_sample_clip_space;
		vec2 texture_eye_sample, xu;
		bool hit_something[3] = bool[](false, false, false);
		bool exceeded_clip[3] = bool[](false, false, false);
		bool hit_a_color[3] = bool[](false, false, false);

		Ray start_ray, current_ray;
		vec4 final_color = vec4(1,0,0,1);
		vec4 color;
		vec3 p;
		
		compute_sub_pixel_rays(ro, rd);
		
		// *** by hand reconstructing texture pixel space of kinect from ray-origin ***
		for (int c = 0;  c < 3; c++){
			vec2 uv = gl_FragCoord.xy / viewport_dims;
			float view = view_from_fragment_component(uv, c);
			mat4 MV = get_modelview_matrix();
			int type;
			int prev_type = NO_SURFACE;
			int classify = IN_FRONT;
			stereo_translate_modelview_matrix(view, MV);

			for (int s = 1; s < raymarch_limit; s++){
				vec2 kinect_uv = vec4((P_kinect * MV * vec4(ro[c], 1.0)).xy/512 + (rd[c] * ray_length * s).xy, 1.0, 1.0).xy;
				float ray_depth_in_kinect_coords = ((P_kinect * MV * vec4(ro[c] + rd[c] * ray_length * s, 1.0)).xyz/512).z;
				mat2 J;
				apply_distortion_model(kinect_uv, xu, J,color_calib);
			
				if (xu.x < -1 ||xu.x > 1||xu.y < -1||xu.y > 1){
					type = NO_SURFACE;
					continue;
				}

				vec2 kinect_px = texture_to_pixel_coordinates(xu, depth_calib);
				//float depth = 65535.0 * texture(depth_image, pixel_to_texture_coordinates(kinect_px, depth_calib)).r;
				float depth = lookup_depth(ivec2(kinect_px));

				if (depth > ray_depth_in_kinect_coords){
					classify = IN_FRONT;
				}else{
					classify = BEHIND;
				}
				
				if (!construct_point(kinect_px, depth, p)){
					type = NO_SURFACE;
				}else{
					type = SURFACE;
				}

				if (prev_type != type && prev_type != NO_SURFACE && type != NO_SURFACE){
					break;
				}else{
					prev_type = type;
				}
			}
			lookup_color(p, color);
			final_color[c] = color[c];
		}

		// remember different modelview matricies for each view inbetween the eyes
		finish_fragment(final_color, gl_FragCoord.z + fi.depth_offset);
	}
}
