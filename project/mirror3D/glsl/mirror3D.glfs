#version 330 core

#define OUT_OF_BOUNDS 1
#define DIVISION_BY_ZERO 2
#define DIVERGENCE 3
#define MAX_ITERATIONS_REACHED 4

uniform bool render_quads;
uniform int coloring;
uniform sampler2D depth_image;
uniform sampler2D distortion_map;
uniform sampler2D color_image;
uniform int y2;

// this is adapted point.glfs

// vertex_position[4] contains position of passed triangle strip: t1: 0,1,2 - t2: 1,2,3 
in POINT_FS {
	vec4 color;
	float depth_offset;
	vec3 normal;
} fi;

// ***** begin interface of camera.glsl *******************************
#define CONVERGENCE 0
#define SUCCESS 0
uniform float inversion_epsilon;
struct calibration
{
	int w;
	int h;
	float max_radius_for_projection;
	vec2 dc;
	float k[6];
	float p[2];
	float skew;
	vec2 c, s;
};
vec2 image_to_pixel_coordinates(in vec2 x, in calibration calib);
vec2 pixel_to_image_coordinates(in vec2 p, in calibration calib);
vec2 texture_to_pixel_coordinates(in vec2 t, in calibration calib);
vec2 pixel_to_texture_coordinates(in vec2 p, in calibration calib);
int apply_distortion_model(in vec2 xd, out vec2 xu, out mat2 J, in calibration calib);
int apply_distortion_model(in vec2 xd, out vec2 xu, out mat2 J, float epsilon, in calibration calib);
int invert_distortion_model(in vec2 xu, inout vec2 xd, bool use_xd_as_initial_guess, in calibration calib);
// ***** end interface of camera.glsl *********************************

// ***** begin interface of fragment.glfs *****************************
uniform float gamma = 2.2;
void finish_fragment(vec4 color);
void finish_fragment(vec4 color, float depth);
// ***** end interface of fragment.glfs *******************************

// ***** begin interface of holo_disp.glfs ****************************
void compute_sub_pixel_rays(out vec3 ro[3], out vec3 rd[3]);
bool finalize_sub_pixel_fragment(in vec3 rgb, in vec3 depth);
// ***** end interface of holo_disp.glfs ******************************

// ***** begin interface of view.glsl *********************************
mat4 get_modelview_matrix();
mat4 get_projection_matrix();
mat4 get_inverse_projection_matrix();
mat4 get_modelview_projection_matrix();
mat4 get_inverse_modelview_matrix();
mat4 get_inverse_modelview_projection_matrix();
mat3 get_normal_matrix();
mat3 get_inverse_normal_matrix();
// ***** end interface of view.glsl ***********************************

// ***** begin interface of rgbd.glsl *********************************
uint get_depth_width();
uint get_depth_height();
uint lookup_depth(ivec2 xp);
bool construct_point(in vec2 xp, in float depth, out vec3 p);
bool lookup_color(vec3 p, out vec4 c);
bool lookup_color(vec3 p, float eps, out vec4 c);
// ***** end interface of rgbd.glsl ***********************************

// ***** begin interface of mirror3D.glsl *****************************
vec3 ray_trace_pixel(vec3 ro, vec3 rd, out float depth);
mat4 kinect_projection_matrix(float fx, float fy, float cx, float cy, int image_height, float near_clip, float far_clip);
mat4 get_model_view_matrix_translation(vec3 ro);
void march_along(vec3 ro, vec3 rd, out vec4 color, out float depth);
vec4 kinect_to_world_space(vec2 uv);
vec2 world_to_kinect_space(vec3 world_pos);
bool map_sample_to_uv(in vec3 ro, out vec2 xd);
// ***** end interface of mirror3D.glsl *****************************

uniform calibration color_calib;
uniform calibration depth_calib;

void main()
{
	// pure coloring
	if (coloring == 0){
		finish_fragment(fi.color, gl_FragCoord.z + fi.depth_offset);
	
	// calculating normals
	} else if (coloring == 1) {

		finish_fragment(vec4(fi.normal.xyz * 10000, 1.0), gl_FragCoord.z + fi.depth_offset);
	
	// ray marching
	} else if (coloring == 2) {
		vec3 ro[3],rd[3];
		vec4 rgb = vec4(0.0);
		vec3 depth;
		compute_sub_pixel_rays(ro, rd);
		
		for (int i; i < 3; i++){
			ro[i] = vec3(world_to_kinect_space(ro[i]), 0); // 1. use sample location in kinect space
			march_along(ro[i], rd[i], rgb, depth[i]);
		}
		finish_fragment(rgb, gl_FragCoord.z + fi.depth_offset);
	}else if (coloring == 3) {
		//finish_fragment(texture(color_image, pixel_to_image_coordinates(gl_FragCoord.xy, color_calib)));
		vec3 ro[3], rd[3];
		vec4 hit_color, final_color;
		compute_sub_pixel_rays(ro, rd);
		lookup_color(ro[0] + rd[0]*2, hit_color);
		
		final_color.x = hit_color.x;
		lookup_color(ro[1] + rd[1]*2, hit_color);

		final_color.y = hit_color.y;
		lookup_color(ro[2] + rd[2]*2, hit_color);

		// remember different modelview matricies for each view inbetween the eyes
		finish_fragment(hit_color, gl_FragCoord.z + fi.depth_offset);
	}
}