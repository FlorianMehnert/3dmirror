#version 330 core

uniform bool render_quads;
uniform int coloring;
uniform sampler2D depth_image;
uniform sampler2D distortion_map;

// *** adapted point.glfs ***

// vertex_position[4] contains position of passed triangle strip: t1: 0,1,2 - t2: 1,2,3 
in POINT_FS {
	vec2 uv;
	vec4 color;
	float depth_offset;
	vec3 normal;
	vec3 debug_color;
} fi;

//***** begin interface of camera.glsl ***********************************
#define CONVERGENCE 0
#define SUCCESS 0
uniform float inversion_epsilon;
struct calibration
{
	int w;
	int h;
	float max_radius_for_projection;
	vec2 dc;
	float k[6];
	float p[2];
	float skew;
	vec2 c, s;
};
vec2 image_to_pixel_coordinates(in vec2 x, in calibration calib);
vec2 pixel_to_image_coordinates(in vec2 p, in calibration calib);
vec2 texture_to_pixel_coordinates(in vec2 t, in calibration calib);
vec2 pixel_to_texture_coordinates(in vec2 p, in calibration calib);
int apply_distortion_model(in vec2 xd, out vec2 xu, out mat2 J, in calibration calib);
int apply_distortion_model(in vec2 xd, out vec2 xu, out mat2 J, float epsilon, in calibration calib);
int invert_distortion_model(in vec2 xu, inout vec2 xd, bool use_xd_as_initial_guess, in calibration calib);
//***** end interface of camera.glsl ***********************************

//***** begin interface of fragment.glfs ***********************************
uniform float gamma = 2.2;
void finish_fragment(vec4 color);
void finish_fragment(vec4 color, float depth);
//***** end interface of fragment.glfs ***********************************

//***** begin interface of holo_disp.glfs ***********************************
void compute_sub_pixel_rays(out vec3 ro[3], out vec3 rd[3]);
bool finalize_sub_pixel_fragment(in vec3 rgb, in vec3 depth);
//***** end interface of holo_disp.glfs ***********************************

//***** begin interface of view.glsl ***********************************
mat4 get_modelview_matrix();
mat4 get_projection_matrix();
mat4 get_inverse_projection_matrix();
mat4 get_modelview_projection_matrix();
mat4 get_inverse_modelview_matrix();
mat4 get_inverse_modelview_projection_matrix();
mat3 get_normal_matrix();
mat3 get_inverse_normal_matrix();
//***** end interface of view.glsl ***********************************

//***** begin interface of rgbd.glsl ***********************************
uint get_depth_width();
uint get_depth_height();
uint lookup_depth(ivec2 xp);
bool construct_point(in vec2 xp, in float depth, out vec3 p);
bool lookup_color(vec3 p, out vec4 c);
bool lookup_color(vec3 p, float eps, out vec4 c);
//***** end interface of rgbd.glsl ***********************************

uniform calibration depth_calib;

vec3 rayTracePixel(vec3 ro, vec3 rd, out float depth) {
	vec3 pos, nor; // hit position and normal
	vec3 col;
	int mat_id; // material ID
	//float t = intersect(ro, rd, pos, nor, mat_id);
	float t = 0.1;
	col = vec3(1.0, 0, 1.0);
	if(mat_id != -1) {
		// get color and texture coordinates depending on material
		vec4 material = vec4(1.0, 0.1, 0.1, 0.05); // add actual color calculation probabily just take given color
		
		/*
		somehow find out what the color is we collided with
		vec2 uv = get_texcoords(pos, mat_id);
		*/
		
		vec3 albedo = material.rgb;
		
		// lighting - probably not to be hardcoded :)
		//color = compute_illumination(pos, nor, rd, shadow_factor, albedo);
		col = vec3(1.0, 0.1, 0.1);
	}
	
	vec4 pos_clip = get_modelview_projection_matrix() * vec4(pos, 1.0);
	depth = 0.5*(pos_clip.z / pos_clip.w) + 0.5;
	
	return col; 
}

void march_along(vec3 ro, vec3 rd, out vec3 color, out float depth){
	vec3 sample_point;
	const int max_steps = 100;
	const float max_distance = 100.0;

	float depth_threshold = texture(depth_image, gl_FragCoord.xy / vec2(textureSize(depth_image, 0))).r;
	float t = 0.0; // stepsize
	depth = 0.0;

	for (int i = 0; i < max_steps; i++) {
		sample_point = ro + rd * t; // ro and rd are in kinect coordinate system
		depth = texture(depth_image, (get_projection_matrix()*get_modelview_matrix()*vec4(sample_point.xy, 1.0, 1.0)).xy).r;
		if (depth < depth_threshold || t > max_distance) {
			break;
		}
		t += 0.01; // maybe adjust step size
	}

	if (depth < depth_threshold) {
		
		// intersection found, do shading calculations here
		vec3 intersection_point = ro + rd * t;
		// perform shading calculations...
        
		//return texture(color_image)vec4(1.0, 1.0, 1.0, 1.0); // Example color
		color = vec4(1.0, 0.0, 0.0, 1.0).xyz;

		
	} else {
		// No intersection found
		discard;
	}
}

// intersect with 2d plane
bool intersect_plane(vec3 ro, vec3 rd, vec3 p1, vec3 p2) {
    // Calculate the plane normal by taking the cross product of vectors from planePoint1 to planePoint2 and planePoint1 to the ray origin
    vec3 plane_normal = normalize(cross(p2 - p1, p1 - ro));

    // Calculate the denominator of the parametric form of the line equation
    float denom = dot(plane_normal, rd);

    // If the denominator is zero, the line is parallel to the plane
    if (abs(denom) < 0.001) {
        return false;
    }

    // Calculate the vector from any point on the plane to the ray origin
    vec3 p0_to_plane = p1 - ro;

    // Calculate the distance from the ray origin to the plane along the ray direction
    float t = dot(p0_to_plane, plane_normal) / denom;

    // If t is positive and within the bounds of the plane, the line intersects the plane
    if (t > 0.0) {
        // Calculate the intersection point
        vec3 intersection_point = ro + t * rd;

        // Check if the intersection point lies within the bounds of the plane
        float d1 = dot(intersection_point - p1, p2 - p1);
        float d2 = dot(intersection_point - p2, p1 - p2);

        if (d1 >= 0.0 && d2 >= 0.0) {
            return true;
        }
    }
    return false;
}


void raymarch_detphtexture_from_anywhere(vec3 ro, vec3 rd, out vec3 color, out float depth){
	vec3 sample_point;
	const int max_steps = 100;
	const float max_distance = 100.0;
	bool previous_sample_type = false; // no surface
	
	// plane intersection with predefined rgb image -> if none then discard
	// what we actually want is an intersection
	if (!intersect_plane(ro, rd, vec3(-3.53553, 2.91328, 3.3), vec3(3.53553, -2.91328, 3.3))){
		discard;
	}
	else{

	}
}

void main()
{
	// pure coloring
	if (coloring == 0){
		finish_fragment(fi.color, gl_FragCoord.z + fi.depth_offset);
	
	// calculating normals
	} else if (coloring == 1) {

		// TODO: why is this factor 10000 -> pretty easy: small triangle = small normal -> only relative matters
		finish_fragment(vec4(fi.normal.xyz * 10000, 1.0), gl_FragCoord.z + fi.depth_offset);
	
	// ray marching
	} else if (coloring == 2) {
		vec3 ro[3], rd[3];
		vec3 rgb = vec3(0.0);
		vec3 depth;

		compute_sub_pixel_rays(ro, rd);
		for (int i; i < 3; i++){
			march_along(ro[i], rd[i], rgb, depth[i]);
		}

	// simply displaying the depth texture - zoom in to existing geometry patch to fully view it
	} else if (coloring == 3) {
		vec2 texCoords = gl_FragCoord.xy / vec2(512);
		float depthValue = texture(depth_image, texCoords).r;
		finish_fragment(vec4(depthValue, 0, 0, 1.0), gl_FragCoord.z);
	} else if (coloring == 4) {
		
		// Calculate texture coordinates based on fragment position
		vec2 texCoords = gl_FragCoord.xy / vec2(textureSize(depth_image, 0));

		// sample at the WORLD POSITION of the depth texture
		vec4 coordinate = get_inverse_projection_matrix() * get_inverse_modelview_matrix() * vec4(texCoords, 1.0, 1.0);
		vec4 color;
		lookup_color(coordinate.xyz, color);
		
		finish_fragment(color, gl_FragCoord.z);
	}
}